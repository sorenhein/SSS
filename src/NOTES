Is ResConvert::increment actually correct, or do we get too few
per group?!

Trick compression
-----------------
setByProduct is pretty ugly.
Find some syntactic sugar, and then Tricks are done.

Cover stats
-----------
ProductStats output the table by depth (#tops used) across horizontally.

Canonical products
------------------
ProductMemory:
Length 6, only highest top (out of 3) set is in some sense the same
as there were only 2 tops (the lowest is there and empty).
Then ProductMemory would give back a ProductUnit consisting of the
pointer to the 2-top one and an offset of 1.
The one using that product would have to take it into account somehow.

ProductMemory no longer needs the counters as they are in ProductStats.

When examining strategies, shift them down as far as possible,
as this reduces the number of covers to consider.

Speed
-----
Delete the old symmetrics and manuals.

The various TODO's in the covers and sub-directories.

Names of cards
--------------
Opponents' cards seem to live in ranks/Opponents.
Maybe we shouldn't use HH as in 4/24, but actualy KQ.
Maybe all we really need is to interrogate Opponents?
It seems to use external ranks in rankInfo[r].

- Where does the actual name of the card come from?  Ranks?

Verbals automatically
=====================

* Try higher depths, both greedily and verbally
* Control in general by the input flag
* The depth (#explicit tops) should be a control parameter somewhere

Verbals of strategy wins
========================
* Also output differences between two strategies
  - As text, maybe mainly actual combinations (Hx, HHx, ...)
  - In a table (as Unicode text, HTML, ...)
  
* Store and calculate in the compressed format of Study?  Can we
  even subtract stuff directly in that domain?


2022-01-15
==========
Optimizations to give up or postpone:

1. Early consolidation
   * consolidate() is only called internally in Slist and in 5 places
     - End of adapt: lessEqualCompleteBasic, if 2+ strategies
     - End of reduceByResults if something changed:
       lessEqualCompleteStudied or lessEqualPrimaryStudied
     - End of expand, if list has become unordered:
       lessEqualCompleteStudied or lessEqualPrimaryStudied
     - multiply by a Strategy, if consolidateFlag, lessEqualMethod
       - Called from Strategies::reactivate, once without and once with c.
         After multiplying simple strategy on.
         lessEqualPrimaryStudied.
       - Looks like only place that consolidates.
     - End of purgeRanges, if something erased:
       lessEqualPrimaryStudied

I think we need a gentler compare for intermediate consolidations.
Something is only dominated if both tricks and winner are dominated.

In Result, things to look at:
*= not sure what to do here.  Flag ambiguity and study it?
+= should perhaps assert that there is no ambiguity.
compareComplete: soft version
compareInDetail: soft version


THOUGHTS ON PARTITIONING

Four criteria to consider:

1. Ordered: North has the highest of the NS cards (or both NS are void).

2. Canonical: North has the >= highest count of each rank among NS down 
   to the first one where it makes a difference.  So always ordered.
   If there are any irrelevant low cards, then these are ordered
   within ranks, but there may be irrelevant ranks.

3. Minimal: Canonically ordered.  Needs itself for at least one strategy.  
   Everything below the corresponding rank is ordered.

Later on we will only solve canonicals for the user, so there is little
point (other than pride) in solving non-canonicals for ranks.

I think we cannot reach a non-canonical from a canonical one.  We might
get a rotation, but that doesn't alter the fact.

We wouldn't solve a non-minimal canonical for the user.  But a minimal
canonical might need a non-minimal canonical, I think.  Or not?

We can solve everything up to <= 9 cards and keep it, even if there are
quite a few strategies.

For a 13-card combination that needs a very large number of strategies,
as long as we can calculate it:  We can look at the number of 
strategies if we cut off ranks ever higher, and stop when the number
of trick-distinct strategies is small enough that we're willing to
solve for it.  Then it's a reference to that strategy.

For exactly 10 cards with a South void, we might hamper 13-carders
by limiting the number of strategies that way.  Or not?

If we only rank-solve canonicals, presumably we have fewer rank
problems and fewer ranked strategies as well.  So testing might be
more benign?

2022-01-07
==========

All old tests I can think of:

Play average 3.44
Play average 7.93
Play average 15.51
Play average 27.03
Play average 43.36
Play average 65.51
Play average 94.54

CombTest errors
---------------

WARNING      229 uses non-minimals
MISMATCH    2980 minimals don't add up

Other checks not implemented yet
--------------------------------
* Ranks: If NS" and N"S, also N'S' and nothing else, etc.

* Unranked strategies should all be among ranked ones, and no
  ranked one should go away in terms of its number of tricks


Ideas against errors
--------------------

I'm beginning to think that the only way to fix the rank stuff is to
do all calculations up to the last step of a trick using only complete
dominances, i.e. tricks do not count more than ranks.

Then in the end we can think of:
- Making small cards irrelevant
- Consolidating also on tricks alone

Indirect influence
..................

It would be nice if all WARN cases lead to the same kind of MISMATCH.
But four of them (up to 11 cards) don't lead to a mismatch at all.
They're all in a way the same.

11/53816, AJ6 / T875
7 strategies, of which 4 use T, 2 use 6 and 1 uses 7.
When we drop the 5 (11/53818, AJ6 / T874), it's the same.

When we drop the 6 (11/53830, AJ5 / T874), we'd expect the same.
But we only get 5 strategies now.

In 11/53816, it is possible to derive a strategy from the start T9J,
leaving A6 / 875.  If it loses to an honor (d=8, H94/H), we can still
finesse with the 87 without the 6.

Against d=11 (KQ94/void) after this start, we have A6 / 875 missing KQ4.
Here we can take 3 tricks using the six.  So the strategy survives,
as it takes the same number of tricks as others.

Later on we find that West can cover, THA leaving J6 / 874 missing
H95.  Here we only take 2 tricks leading to the jack; West hops up
and later scores the 9.

So the strategy "forgets" that it needed the 6 for something.

In 11/53830, if we start T9J leaving A5 / 874, we also get 3 tricks
using the 7 against d=8.  But against d=11 we are left with
A5 / 874 missing KQ6, and now we can only take 2 tricks.  So the
strategy is eliminated completely, as it takes fewer tricks even
though it might have a USP in terms of ranks somewhere.

So it's similar to the premature eliminations below.


Grosvenor gambit
................
9/2076, AK6 / T9
From d = 4 (Hx / Hx), defenders may drop HH on the 9.  Then it looks
like 5/51, AT / K missing QJ, where there is only one solution for
all distributions, 2/AK which translates into the ten.

The defense would never do this from d = 2 (H / Hxx), as it would show
up when we lead the T, so then it would just cost a trick.

From d = 6 (Hxx / H) it would cost a trick if declarer plays for it.
But that possibility is not easily eliminated early on.  When the
defense multiplies 9x and 9H, it will always go for 9x with d = 6.

But even if declarer figured this out, he would still end up in
5/51, this time "knowing" that the central distribution (x/x) is the
only one.  Unfortunately the strategies has 2/AK because cashing the
ace has the result profile 1/A, 2/A, 1/A which lost out to
2/AK, 2/AK, 2/AK due to fewer tricks.

9/2076 refers to 9/2098, AK7 / T6 which only ever uses the king.
The same thing could and does happen here if declarer leads the 6:
The defense may crash the honors.  But declarer can also lead the ten,
sacricifing the card!  Now there is nothing to crash.  Declarer can
get the ten out of the way here and not in 9/2076.

So 9/2098 refers to 9/2164, AK8 / 76 which also uses only the king.

We can in principle keep strategies such as 1A 2A 1A vs 2AK 2AK 2AK
alive within a trick, but it is very unappealing to do this across
tricks.

So maybe we recognize when the parent has a worse profile than a
minimal, and we count (and fix?) these.


Premature reduction
...................

In 9/2645 (AQ/KJ9 missing Txxx), if we start with the 9, we get
#0 the trivial strategy (always needing AKQ), 
#1 9 to A, then overtake Q if the T shows up, wins a rank (AK) for d=3,
loses a rank (QJ) for d=1,
#2 9 to A, then always overtake Q, wins ranks (AK) for d=3,4,
loses ranks (QJ) for d=1,2.

If we start with J (which doesn't make sense), we get the same
trivial strategy #0; we don't get #2 as we can't afford always to
overtake; instead we get #1 which is similar to #1 above but
needing the 9 and not the QJ for d=1.
The #1 from J should lose to the #1 from 9.  But the #1 from 9
has already been eliminated (reduced), so #1 from 9 seems to survive.

This wouldn't show up in a minimals check, as the 9 would seem to
be needed (so 9/2645 would be minimal, needing the 9). The one needing
the jack would presumably be minimal as well.

The only solution seems to be not to reduce before the += step.
How much time and memory does this cost?

Update: Now that we don't lead the jack, it can't happen anymore.


Premature consolidation
.......................

In 7/1595 (KT9/Q) for the start Q J there are two strategies, each 
with pluses and minuses for declarer.  #1 (overtaking) needs 2N' 
in order not to lose on tricks anywhere to #0.  Then d = 7 (Kxx / x)
from Q x and Q A comes into play (1, KQ) and beats d = 7 in both
these strategies, so 2N' is no longer needed.  #0 and #1 survive.

In 7/1599 (KT8/Q), #1 loses on tricks to #0 as the 9 is missing,
even though #1 would win d = 6 on ranks. Again d = 7 is eliminated,
so now #1 would be competitive against #0, but it is too late.

The solution seems to be not to consolidate in the partner += step
already, and to wait for the lead += step (and the LHO *= step).
This probably costs memory and time.  I think I will wait with this
until I've done some other optimizations.  Or actually, only
consolidate away strategy's that are completely dominated, i.e.
every result is <=.

How it shows up: In 7/1595 there are 2 strategies, in the combination
of the two "minimals" only 1 (the same).  There should be 2.

Rare products
.............

In 8/1799 (AT/QJ9 missing Kxx) for the start Q and for d = 7 (Kxx/-),
West can duck and then declarer finesses (#0): 2, 2S as superficially,
only the queen is needed.  Later we multiply with Q K (cover) which
has 3/2NS' (QJT).  West will not cover, so it looks as if 2/2S is 
enough.  But 3/2NS' needs a lot more cards than 2/2S.  Concretely
it is in some sense possible to play Q K A for only 2 tricks by
somehow conceding after winning the jack.

3/2NS' in a sense has a profile of trick-taking capability:
3/2NS', 2/2S', 1/4N.  If we multiply this by 2/2S it should yield
2/2S' and not 2/2S.  The condition is more tricks with 2+ more
constraints in between them.  Then it may be possible to weaken
and still improve on the bound.

A trivial strategy stays trivial.

When adapting, we have a new winner (say 1/C) and a subsequent winner
(say 1/D).  We can make 2/(C*D).  We can also make 1/C or 1/D.
If C is more constrained, then we get 2/C and 1/D (as declarer gets
to choose the less constrained one if he gives up a trick).
1/D is only interesting if it is 2+ more relaxed than C.

In general, we can multiply one profile with another to preserve the
sums of tricks.  Then we can pick the most constrained way to get
a number of tricks (defense chooses).  Then we can prune some
declarer's choices of giving up tricks if it doesn't gain 2+ cards.

Again this takes memory and time.

if (tricks > result.tricks)
{
  if (! winner.empty() &&
      winner.getAbsNumber() + 1 < result.winner.getAbsNumber())
  {
  }
}
else if (tricks < result.tricks)
{
  if (! winner.empty() &&
      result.winner.getAbsNumber() + 1 < winner.getAbsNumber())
  {
  }
}

How it shows up: 3 strategies in 1799, 2 in the only minimal (1799).
In this case the third one shouldn't actually exist.

Overall partitioning
--------------------

* Can characterize solved, ranked combinations as canonical or not,
  and minimal or not (bit vector of bools?)

* CombEntry:cpp, e.g. setMinimal: review

Symmetrization
--------------

* For void starting with 10-13 cards (assuming we solve up to 13
  cards), it's always OK to symmetrize, as we can never get there
  from non-void combinations.  We do this:
  a. If we get above [100] strategies, we start over and only
     look up symmetrized strategies (so 6-8 and 8-6 are done together
     and symmetrized against each other).  Multiply strategy by
     strategy, I think, and don't do a complete cross
  b. In the end, if we are above [16] strategies, we symmetrize
  c. If we know from lookup that something must be symmetric

* A histogram of #strategies shows that we also get large numbers
  when South has a single card, e.g. 11/132887, KJ95 / 7 missing AQT864.
  Maybe it's OK to limit next strategies to symmetric ones, too,
  when South becomes void and there are a lot of next strategies.
  1606 strategies here.

* Symmetrize 11 / 132902, KJ96 / void: From ~ 9619 to 166 strategies.
  Similar to the square root.

* Actually, maybe the way to cut down is to gradually bump up
  the critical rank and eliminate strategies from below, until we
  arrive at a reasonable range?  And check that the eliminated ones
  are covered by trick vectors when we later forget about ranks?

  Like a rolling pruning?  Once cards == 10 are done, go over and
  turn some holdings into references to other because there are
  too many strategies.  So this is a new type, not minimal/
  canonical/oriented, but simplified from one rank to another.
  Just note its own rank, because the referred one also has a rank.


Optimizations
-------------
* If there is a Result per Strategy, equality can be tested first
  in this way.  And then one Result per group (Reduction).
  - One classical lowest result, one that takes history into account
  - In print output, show the result(s)

* Similarly when only < or > is possible.  Take the lowest one and
  its groups.

* Would it be worthwhile to store the minimal numbers in the Strategy
  as well?
  -- Then it would also be in the print output, in the table itself

* Optimize the code for Slist::minimal().  Is it even used?

* Probably Winners can really go away now -- always single-valued?
  MultiResult then too?

* Look at speeding up Slist::equalByMethod.
  Divide completely by size
  assert size(v1) >= size(v2)?

* Also optimize for Strategies == even though it doesn't matter
  - Start at ==, only do upper triangle of matrix

* Is Declarer::greater used?  Is it completely right?

* If space became really tight, the minimals in CombEntry could be
  indices in a central list (careful with multi-threading).  That would
  save the 24-byte overhead in each CombEntry at the cost of two
  4-byte counters and potentially an internal "iterator".  So it
  should save 12-16 bytes per CombEntry, and there are ~ 2m of them,
  so ~ 25 MB.

* Why more than 2x Ranks to Plays and Strategize at the end of output?

* No / limited endl


Ranks stored in tables
----------------------
* Write and read binary files with holdings to run vs. not
* Is it true that a minimal combination does not need non-minimal
  ones to solve?  If not, we would either solve the non-minimal
  ones, or look up the non-minimal one (probably better) and
  map the smaller number of distributions to the current case somehow


Mixed strategies
----------------
In the end we may not have to do so much LP.  EW must find play for
each distribution that work against all NS strategies.  EW get into
trouble when they need to vary their play depending on what NS do.
So we keep track of all plays that work in various situations, and we
take the intersection which is often not empty.

I'm hoping this will also give rise to the mandatory falsecards that
protect not this holding, but some other holding.

Perhaps represent all the NS strategies as some kind of tree with the
branching points that they will actually make use of.

In the end there will be the combinations with mixed potential.  But
I think we can do all the above independent of external constraints.
So we can actually tell in the abstract which combinations have the
potential for mixed strategies, even without knowing the constraints?!


Features
--------
* Distribution::limit, using a struct that Control returns
  - We will fail for now on some HCP values

* Not all features of Control.cpp are implemented yet

* Check sometime that these still work
  - Node optimization (on/off)
  - Strategies *= optimization (on/off)


Semantics, verbal descriptions
------------------------------
* Winning plays/strategies such as "cash ace"
  - Sometimes NS have several ways to reach its optimum; keep them all
* Noting the inequalities on EW plays that are needed to stabilize
  an NS strategy

Bugs
----
Why doesn't it work in Combination to make complete copies of
everything?  It must be some stray pointers, but where?

