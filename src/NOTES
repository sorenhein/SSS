2022-01-07
==========

All old tests I can think of:

Play average 3.44
Play average 7.93
Play average 15.51
Play average 27.03
Play average 43.36
Play average 65.51
Play average 94.54

CombTest errors
---------------

WARN-NONMIN      225    happens in fixMinimals
MISMATCH        2315

Other checks not implemented yet
--------------------------------
* Ranks: If NS" and N"S, also N'S' and nothing else, etc.

* Unranked strategies should all be among ranked ones, and no
  ranked one should go away in terms of its number of tricks


Ideas against errors
--------------------

Grosvenor gambit
................
9/2076, AK6 / T9
From d = 4 (Hx / Hx), defenders may drop HH on the 9.  Then it looks
like 5/51, AT / K missing QJ, where there is only one solution for
all distributions, 2/AK which translates into the ten.

The defense would never do this from d = 2 (H / Hxx), as it would show
up when we lead the T, so then it would just cost a trick.

From d = 6 (Hxx / H) it would cost a trick if declarer plays for it.
But that possibility is not easily eliminated early on.  When the
defense multiplies 9x and 9H, it will always go for 9x with d = 6.

But even if declarer figured this out, he would still end up in
5/51, this time "knowing" that the central distribution (x/x) is the
only one.  Unfortunately the strategies has 2/AK because cashing the
ace has the result profile 1/A, 2/A, 1/A which lost out to
2/AK, 2/AK, 2/AK due to fewer tricks.

9/2076 refers to 9/2098, AK7 / T6 which only ever uses the king.
The same thing could and does happen here if declarer leads the 6:
The defense may crash the honors.  But declarer can also lead the ten,
sacricifing the card!  Now there is nothing to crash.  Declarer can
get the ten out of the way here and not in 9/2076.

So 9/2098 refers to 9/2164, AK8 / 76 which also uses only the king.

We can in principle keep strategies such as 1A 2A 1A vs 2AK 2AK 2AK
alive within a trick, but it is very unappealing to do this across
tricks.

So maybe we recognize when the parent has a worse profile than a
minimal, and we count (and fix?) these.


Premature reduction
...................

In 9/2645 (AQ/KJ9 missing Txxx), if we start with the 9, we get
#0 the trivial strategy (always needing AKQ), 
#1 9 to A, then overtake Q if the T shows up, wins a rank (AK) for d=3,
loses a rank (QJ) for d=1,
#2 9 to A, then always overtake Q, wins ranks (AK) for d=3,4,
loses ranks (QJ) for d=1,2.

If we start with J (which doesn't make sense), we get the same
trivial strategy #0; we don't get #2 as we can't afford always to
overtake; instead we get #1 which is similar to #1 above but
needing the 9 and not the QJ for d=1.
The #1 from J should lose to the #1 from 9.  But the #1 from 9
has already been eliminated (reduced), so #1 from 9 seems to survive.

This wouldn't show up in a minimals check, as the 9 would seem to
be needed (so 9/2645 would be minimal, needing the 9). The one needing
the jack would presumably be minimal as well.

The only solution seems to be not to reduce before the += step.
How much time and memory does this cost?

Update: Now that we don't lead the jack, it can't happen anymore.


Premature consolidation
.......................

In 7/1595 (KT9/Q) for the start Q J there are two strategies, each 
with pluses and minuses for declarer.  #1 (overtaking) needs 2N' 
in order not to lose on tricks anywhere to #0.  Then d = 7 (Kxx / x)
from Q x and Q A comes into play (1, KQ) and beats d = 7 in both
these strategies, so 2N' is no longer needed.  #0 and #1 survive.

In 7/1599 (KT8/Q), #1 loses on tricks to #0 as the 9 is missing,
even though #1 would win d = 6 on ranks. Again d = 7 is eliminated,
so now #1 would be competitive against #0, but it is too late.

The solution seems to be not to consolidate in the partner += step
already, and to wait for the lead += step (and the LHO *= step).
This probably costs memory and time.  I think I will wait with this
until I've done some other optimizations.  Or actually, only
consolidate away strategy's that are completely dominated, i.e.
every result is <=.

How it shows up: In 7/1595 there are 2 strategies, in the combination
of the two "minimals" only 1 (the same).  There should be 2.

Rare products
.............

In 8/1799 (AT/QJ9 missing Kxx) for the start Q and for d = 7 (Kxx/-),
West can duck and then declarer finesses (#0): 2, 2S as superficially,
only the queen is needed.  Later we multiply with Q K (cover) which
has 3/2NS' (QJT).  West will not cover, so it looks as if 2/2S is 
enough.  But 3/2NS' needs a lot more cards than 2/2S.  Concretely
it is in some sense possible to play Q K A for only 2 tricks by
somehow conceding after winning the jack.

3/2NS' in a sense has a profile of trick-taking capability:
3/2NS', 2/2S', 1/4N.  If we multiply this by 2/2S it should yield
2/2S' and not 2/2S.  The condition is more tricks with 2+ more
constraints in between them.  Then it may be possible to weaken
and still improve on the bound.

A trivial strategy stays trivial.

When adapting, we have a new winner (say 1/C) and a subsequent winner
(say 1/D).  We can make 2/(C*D).  We can also make 1/C or 1/D.
If C is more constrained, then we get 2/C and 1/D (as declarer gets
to choose the less constrained one if he gives up a trick).
1/D is only interesting if it is 2+ more relaxed than C.

In general, we can multiply one profile with another to preserve the
sums of tricks.  Then we can pick the most constrained way to get
a number of tricks (defense chooses).  Then we can prune some
declarer's choices of giving up tricks if it doesn't gain 2+ cards.

Again this takes memory and time.

if (tricks > result.tricks)
{
  if (! winner.empty() &&
      winner.getAbsNumber() + 1 < result.winner.getAbsNumber())
  {
  }
}
else if (tricks < result.tricks)
{
  if (! winner.empty() &&
      result.winner.getAbsNumber() + 1 < winner.getAbsNumber())
  {
  }
}

How it shows up: 3 strategies in 1799, 2 in the only minimal (1799).
In this case the third one shouldn't actually exist.

Overall partitioning
--------------------

* Can characterize solved, ranked combinations as canonical or not,
  and minimal or not (bit vector of bools?)

* CombEntry:cpp, e.g. setMinimal: review

Symmetrization
--------------

* For void starting with 10-13 cards (assuming we solve up to 13
  cards), it's always OK to symmetrize, as we can never get there
  from non-void combinations.  We do this:
  a. If we get above [100] strategies, we start over and only
     look up symmetrized strategies (so 6-8 and 8-6 are done together
     and symmetrized against each other).  Multiply strategy by
     strategy, I think, and don't do a complete cross
  b. In the end, if we are above [16] strategies, we symmetrize
  c. If we know from lookup that something must be symmetric

* A histogram of #strategies shows that we also get large numbers
  when South has a single card, e.g. 11/132887, KJ95 / 7 missing AQT864.
  Maybe it's OK to limit next strategies to symmetric ones, too,
  when South becomes void and there are a lot of next strategies.
  1606 strategies here.

* Symmetrize 11 / 132902, KJ96 / void: From ~ 9619 to 166 strategies.
  Similar to the square root.

* Actually, maybe the way to cut down is to gradually bump up
  the critical rank and eliminate strategies from below, until we
  arrive at a reasonable range?  And check that the eliminated ones
  are covered by trick vectors when we later forget about ranks?

  Like a rolling pruning?  Once cards == 10 are done, go over and
  turn some holdings into references to other because there are
  too many strategies.  So this is a new type, not minimal/
  canonical/oriented, but simplified from one rank to another.
  Just note its own rank, because the referred one also has a rank.


Optimizations
-------------
* If there is a Result per Strategy, equality can be tested first
  in this way.  And then one Result per group (Reduction).
  - One classical lowest result, one that takes history into account
  - In print output, show the result(s)

* Similarly when only < or > is possible.  Take the lowest one and
  its groups.

* Would it be worthwhile to store the minimal numbers in the Strategy
  as well?
  -- Then it would also be in the print output, in the table itself

* Optimize the code for Slist::minimal().  Is it even used?

* Probably Winners can really go away now -- always single-valued?
  MultiResult then too?

* Look at speeding up Slist::equalByMethod.
  Divide completely by size
  assert size(v1) >= size(v2)?

* Also optimize for Strategies == even though it doesn't matter
  - Start at ==, only do upper triangle of matrix

* Is Declarer::greater used?  Is it completely right?

* If space became really tight, the minimals in CombEntry could be
  indices in a central list (careful with multi-threading).  That would
  save the 24-byte overhead in each CombEntry at the cost of two
  4-byte counters and potentially an internal "iterator".  So it
  should save 12-16 bytes per CombEntry, and there are ~ 2m of them,
  so ~ 25 MB.

* No / limited endl


Non-batch one-shots
-------------------

* Go from only batch to solving a single distribution from scratch
  a. Basic idea is to make a list of the nodes you'll need
  b. Then make these recursively before you solve this node
  c. A lot of flags are the same, i.e. ranks or not, optimizations
     turned on or not, debugging/checks on/off
  d. Could switch to the minimal one (or one of them) and only
     solve this

Ranks stored in tables
----------------------
* Write and read binary files with holdings to run vs. not
* Is it true that a minimal combination does not need non-minimal
  ones to solve?  If not, we would either solve the non-minimal
  ones, or look up the non-minimal one (probably better) and
  map the smaller number of distributions to the current case somehow


Mixed strategies
----------------
In the end we may not have to do so much LP.  EW must find play for
each distribution that work against all NS strategies.  EW get into
trouble when they need to vary their play depending on what NS do.
So we keep track of all plays that work in various situations, and we
take the intersection which is often not empty.

I'm hoping this will also give rise to the mandatory falsecards that
protect not this holding, but some other holding.

Perhaps represent all the NS strategies as some kind of tree with the
branching points that they will actually make use of.

In the end there will be the combinations with mixed potential.  But
I think we can do all the above independent of external constraints.
So we can actually tell in the abstract which combinations have the
potential for mixed strategies, even without knowing the constraints?!


Features
--------
* Distribution::limit, using a struct that Control returns
  - We will fail for now on some HCP values

* Not all features of Control.cpp are implemented yet

* Check sometime that these still work
  - Node optimization (on/off)
  - Strategies *= optimization (on/off)


Semantics, verbal descriptions
------------------------------
* Winning plays/strategies such as "cash ace"
  - Sometimes NS have several ways to reach its optimum; keep them all
* Noting the inequalities on EW plays that are needed to stabilize
  an NS strategy

* Verbal description of NS strategy
  - Minterms?

8/1110, A97 / KQJ8
Take all 4 tricks

9/5084, AQ8 / -
Always take at least 1 trick
Take 2 tricks when the kind is at most doubleton

10/15195, AQ5 / 986
Take 2+ tricks if the suit splits 2-2 or the king is onside.
Take 3 tricks if both conditions apply.

Take 2 tricks if West has 2+ cards of the singleton kig.

Take 2 tricks if West has the king of jack-ten.
Take 3 tricks if West has KH.

11/40890, AQJ984 / 65
Take all 6 tricks if the king is onside.
Singleton.

Bugs
----
Why doesn't it work in Combination to make complete copies of
everything?  It must be some stray pointers, but where?

