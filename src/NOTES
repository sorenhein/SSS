Just one type of SINGULAR, as we detect the side later anyway.

* In Heuristics, there can be nested lengths, so 2-4 and 3-3 additionally!
  11/159468
* In CoverStore move the many calls into one Cover call?


Text covers
-----------
Product.cpp from about line 700: Improve.
Make all texts more human to read.

Output a "where" line for the actual solutions.
Only when it is of interest.
Honor codes used in ranks and plays could be consistent with covers.
HH only used down to JT, then hh instead.

Is it always right only to include in CoverStore covers that are 
explainable?

Check the complexity/count score.  1 if exact, > 1 if HhGgx...
Taking into account symmetry (Either) of course.

Combine within say J: All Wests singular combined onto one line.

Remove [...] and see count of different covers


Reduce the size of CoverStore
-----------------------------
Can skip Top/Any as range (completely) for g = 4, except that 
Manual seems to use them

Complexities
------------
Check that complexities are now homogeneous
- SINGULAR are OK



Text          614295  0.00
Untext        354887  3.41

Singular      171598  3.00
Singfull        8674  3.00

Top2 eq        37511  4.00
Top2 eqL       21547  3.00
Top2 eqV        6364  6.17
Any2 eq        22141  4.00
Any2 eqL       36947  3.00
Any2 eqV        6762  6.18
Top2 eq+        3653  4.00
Any2 eq+        1626  4.00

Top3 eq         6690  6.00
Top3 eqL        3930  3.00
Top3 eqV         476  8.10
Any3 eq         2495  6.00
Any3 eqL       19626  3.00
Any3 eqV         221  8.17
Top3 eq+         856  6.00
Any3 eq+         163  6.00

Top4 eq          707  8.00
Top4 eqL         630  3.00
Top4 eqV           8 10.75
Any4 eq           17  8.00
Any4 eqL        2113  3.00
Any4 eqV           0
Top4 eq+          75  8.00
Any4 eq+           0

Rest              57  5.61

* We would lose very few covers by limiting ourselves to these.
* The singular ones should be matchable with C++ first.
* TopN eq: The N highest tops are set to fixed values.
* TopN eqL: The same, but also L (though not singular,
  so complexity should probably not be 3)
* TopN eqV: The same, but L is a range and not a single value
* TopN eq+: N tops, N-1 of which constant and one a range.  No L


In RowMatches, cleanup.

Probably something wrong again with classification of strategies
as symmetric or not (see counts of new vs old mode == 4).

mode == 4: Pick the best solution from a list.

Also look at 3*3 for mode == 2 and 3.  See the score of the heuristic
alone. Maybe diagram of log10(time) and complexity.

Differences g = 4 simple length-1 heuristic to 3*3
==================================================
6/546 #1:
"Either opponent has a singleton": 2
"Neither opponent is void"       : 3
So in this specific case of len = 3, range = 1-2, we can change
the text output (and can a complexity point).

8/5051 #0:
West has the ace + West has a doubleton: 2/8 + 2/6 = 4/14
Q without A, or West has a doubleton: 4/8 + 2/6 = 6/14
So both have weight 14, but one has lower complexity.

Comparing g = 2 to g = 4 (so both are heuristic; then optimal vs fast).
Most of the remaining loss occurs when no OR can be generated,
although I guess the OR could come from the heuristic.
Actually the old g = 2 was missing a few symmetric covers,
so g = 4 actually beats g = 2 sometimes.

 c     same     diff   diffOr
 4        4        0        0
 5       27        0        0
 6       97       16        0
 7      381      106        0
 8     1753      322       11
 9     8399      768      473
10    33947     3629     5565
11   139667    18123    52711

               10955   137334

Comparing g = 0 to g = 4 (so fastest vs best)

 c     same     diff   diffOr
 4        4        0        0
 5       27        0        0
 6       97       16        0
 7      353      134        0
 8     1515      536       35
 9     6772     1917      951
10    25206     9045     8890
11    94697    49829    65975

              148367   305526

Comparing g = 0 to g = 2 (so heuristic vs best/no heuristic).
Two thirds of the quality loss happens from 0 to 2,
one third from 2 to 4.

 c     same     diff   diffOr
 4        4        0        0
 5       27        0        0
 6      113        0        0
 7      459       28        0
 8     1848      214       24
 9     7767     1159      714
10    29724     6005     7412
11   121654    35519    53328

              118589   187015



So 3/4 of the problem is in the lack of OR ability, it seems.

9/15113, #2
Singleton ace does fit with "2-3, 1 of top, unused, 0 of third".
Probably they also have different canonical shifts?
FactoredProduct::sameTops

8/5907  Can't turn "West doubleton", "West AKx(x)" into
        "West doubleton, or West AK-any"

Texts
7/1683  "East has at most a doubleton" -> "West is not void"

8/4812, #2
Not sure about the output "West has x(x)"
More like "1-2 cards with no h".

* Can also split the completely symmetric tricks by lengths,
  and only match with symmetric covers length-by-length and combine

10/44451 #0 is now familiar, so may look at this.

11/136262 #4: There is a difference between d = 33 (QJ9) and 
say d = 29 (QJ6).  Yet we apparently never win a trick with the 7.
For now I just flag these rank issues.

- Potentially AQT-any occurs and should get a lower complexity,
  similar to when the exact combination is known?
- Maybe guess by first trying all single-top covers first,
  then whatever length-only still fits

6/542, KJT/- miss AQ9
T takes a trick, but in #0 only the K matters in Tricks.
So actually the trick-taker is not the perfect indicator of ranks.



There are really only 4 combinations with depth == 5:
11/132860          78
KJ975/- missing AQT864

11/132887        1552
KJ95/7 missing AQT864

11/133103         836
KJ75/9 missing AQT864

11/135047         111
K975/J missing AQT864

There are more with depth == 4.  Here are the ones >= 100:
100   11/135289 K75/J94 miss AQT86
100   11/135291 K74/J95
102   11/136181 KT75/7 missing AHH964
104   11/136127 KT85/7
105   11/136139 KT86/5 missing AHH974
[deleted 40]
228   11/132863
228   11/132865
228   11/132875
331   11/123101 KQT6/8 miss AJ97xx

11/123101 -D 4: #0 seems to be cached, but from where?!

Add the "x" lowest top?

Consider allowing somehow the excluded covers that are splittable
into a symmetric part within the overall symmetry, and an
anti-symmetric part that is completely outside of it.


Differences in new partition:

11/130538: Comes up with 2-3 or (West 1+H without A),
  which adds 2+1 cases.  (West HH any) would have been better as it
  adds 4 cases, but it has fewer overlaps with 2-3 length.
  So we should somehow take into account that the tops are incremental
  to the length, and only the additions count.
11/137056: Starts out OK ("East has at most a tripleton").

So if we have the length result, perhaps make that row already.
Then findHeaviest attempts to add to it.
But then we cannot use additions to tell whether or not there was
overlap...


Examples of sub-optimalities:

- 11/130538, K985/Q7 miss AHH64
  Old #9 effectively [12/4]
  * West has a doubleton [10]
  * East has a doubleton [10]; or
    [West has both HH any length]
  * [West has the singleton H]
  * West has the singleton [ace] [1]

  New #9 effectively [17/3]
  SYMM
  * Each opponent has 2-3 cards [20]
  * Either opponent has the singleton honor [2]

  ASYMM
  * [West has the singleton H]
  * [West has AHH fourth]
  * East is void [1]
  * [West has HH doubleton]

  In this particular case,
  best length-only: 2-3
  best tops-only: W HH
  Combination works

  2-3 or W HH
  W stiff H, stiff HH, stiff A


SurvivorList is not going to be useful to reduce result vectors:
It maps full to reduced distributions when a NS rank (or two) disappears.
It does not take into account that some ranks are not needed.

D == 2
trivial            187
asymmetric       29770
symmetric        42627
general         116436

Maybe we do need to reintroduce the 0th rank, 11/124454 would benefit
from "East has x".  Perhaps
* Each opponent has 2-3 cards (4-11)
* West has the H and not the x (3, 7, 11, 15)
* West has 4 cards including all 3 hhh's

11/120243, KQJ4 / 765
#0 manual: East has at most a tripleton -> West is not void?

Why do tableaux consume so much memory?  Do they?  Can we make a "frame"
or "skeleton" that gets stored afterward?

* Store something pre-calculated in files, such as
  - Complexity
  - Highest-weight one or few products to use
  - Only covers to consider

Strategy depth statistics

 nom | act     0     1     2     3     4     5     Sum
------------------------------------------------------
         0  2356     -     -     -     -     -    2356
         1  8753 26888     -     -     -     -   35641
         2  2659 45004 52083     -     -     -   99746
         3   176  8110 39033 45132     -     -   92451
         4     -   202  2748 11861 17787     -   32598
         5     -     -     8   106   516  2577    3207
------------------------------------------------------
       Sum 13944 80204 93872 57099 18303  2577

This is for a run at depth == 2.

    actual symmstrat otherstrat  cachehit cachemiss 
         0 13944         -       13884      60
         1 22646     57558       78591    1613
         2  6224     87648       88213    5659
         3  1996     55103
         4   662     17641
         5    78      2499

We could check how many of the cache misses are symmetricPrimary.
Also, time in Covers.cpp per depth, get average per strategy.
Presumably depth == 5 is the worst by far.



Deeper strategies
-----------------
For the future it's a decent test of ranks to compare:
symmetrization of tricks after full run (Combination::strategize
at the end) vs. ongoing (symmOnlyFlag).

Why does 8/4922 change when (probably) we change the bug in
Plays.cpp line 187?  (Should also change line 180.)
This is another decent test of ranks.

Shifts
------
* Find a way to shift strategies down/up
  - Need access to other distributions and their tableaux
  - Perhaps a non-canonical distribution has pointers to all its
    possible simpler versions
  - Then we simplify to the canonical one and compare the tricks
  - If the same, we don't solve and instead use that tableau
  - Above, this should collapse the columns 0 and 1 upward

* Think about storing the actually used covers and results in files?

11/158948 has four out of five strategies that are the same in terms
of tricks, but differ in terms of detailed ranks.

Verbals of strategy wins
========================
* Also output differences between two strategies
  - As text, maybe mainly actual combinations (Hx, HHx, ...)
  - In a table (as Unicode text, HTML, ...)
  
2022-01-15
==========
Optimizations to give up or postpone:

1. Early consolidation
   * consolidate() is only called internally in Slist and in 5 places
     - End of adapt: lessEqualCompleteBasic, if 2+ strategies
     - End of reduceByResults if something changed:
       lessEqualCompleteStudied or lessEqualPrimaryStudied
     - End of expand, if list has become unordered:
       lessEqualCompleteStudied or lessEqualPrimaryStudied
     - multiply by a Strategy, if consolidateFlag, lessEqualMethod
       - Called from Strategies::reactivate, once without and once with c.
         After multiplying simple strategy on.
         lessEqualPrimaryStudied.
       - Looks like only place that consolidates.
     - End of purgeRanges, if something erased:
       lessEqualPrimaryStudied

I think we need a gentler compare for intermediate consolidations.
Something is only dominated if both tricks and winner are dominated.

In Result, things to look at:
*= not sure what to do here.  Flag ambiguity and study it?
+= should perhaps assert that there is no ambiguity.
compareComplete: soft version
compareInDetail: soft version


THOUGHTS ON PARTITIONING

Four criteria to consider:

1. Ordered: North has the highest of the NS cards (or both NS are void).

2. Canonical: North has the >= highest count of each rank among NS down 
   to the first one where it makes a difference.  So always ordered.
   If there are any irrelevant low cards, then these are ordered
   within ranks, but there may be irrelevant ranks.

3. Minimal: Canonically ordered.  Needs itself for at least one strategy.  
   Everything below the corresponding rank is ordered.

Later on we will only solve canonicals for the user, so there is little
point (other than pride) in solving non-canonicals for ranks.

I think we cannot reach a non-canonical from a canonical one.  We might
get a rotation, but that doesn't alter the fact.

We wouldn't solve a non-minimal canonical for the user.  But a minimal
canonical might need a non-minimal canonical, I think.  Or not?

We can solve everything up to <= 9 cards and keep it, even if there are
quite a few strategies.

For a 13-card combination that needs a very large number of strategies,
as long as we can calculate it:  We can look at the number of 
strategies if we cut off ranks ever higher, and stop when the number
of trick-distinct strategies is small enough that we're willing to
solve for it.  Then it's a reference to that strategy.

For exactly 10 cards with a South void, we might hamper 13-carders
by limiting the number of strategies that way.  Or not?

If we only rank-solve canonicals, presumably we have fewer rank
problems and fewer ranked strategies as well.  So testing might be
more benign?

2022-01-07
==========

All old tests I can think of:

Play average 3.44
Play average 7.93
Play average 15.51
Play average 27.03
Play average 43.36
Play average 65.51
Play average 94.54

CombTest errors
---------------

WARNING      229 uses non-minimals
MISMATCH    2980 minimals don't add up

Other checks not implemented yet
--------------------------------
* Ranks: If NS" and N"S, also N'S' and nothing else, etc.

* Unranked strategies should all be among ranked ones, and no
  ranked one should go away in terms of its number of tricks


Ideas against errors
--------------------

I'm beginning to think that the only way to fix the rank stuff is to
do all calculations up to the last step of a trick using only complete
dominances, i.e. tricks do not count more than ranks.

Then in the end we can think of:
- Making small cards irrelevant
- Consolidating also on tricks alone

Indirect influence
..................

It would be nice if all WARN cases lead to the same kind of MISMATCH.
But four of them (up to 11 cards) don't lead to a mismatch at all.
They're all in a way the same.

11/53816, AJ6 / T875
7 strategies, of which 4 use T, 2 use 6 and 1 uses 7.
When we drop the 5 (11/53818, AJ6 / T874), it's the same.

When we drop the 6 (11/53830, AJ5 / T874), we'd expect the same.
But we only get 5 strategies now.

In 11/53816, it is possible to derive a strategy from the start T9J,
leaving A6 / 875.  If it loses to an honor (d=8, H94/H), we can still
finesse with the 87 without the 6.

Against d=11 (KQ94/void) after this start, we have A6 / 875 missing KQ4.
Here we can take 3 tricks using the six.  So the strategy survives,
as it takes the same number of tricks as others.

Later on we find that West can cover, THA leaving J6 / 874 missing
H95.  Here we only take 2 tricks leading to the jack; West hops up
and later scores the 9.

So the strategy "forgets" that it needed the 6 for something.

In 11/53830, if we start T9J leaving A5 / 874, we also get 3 tricks
using the 7 against d=8.  But against d=11 we are left with
A5 / 874 missing KQ6, and now we can only take 2 tricks.  So the
strategy is eliminated completely, as it takes fewer tricks even
though it might have a USP in terms of ranks somewhere.

So it's similar to the premature eliminations below.


Grosvenor gambit
................
9/2076, AK6 / T9
From d = 4 (Hx / Hx), defenders may drop HH on the 9.  Then it looks
like 5/51, AT / K missing QJ, where there is only one solution for
all distributions, 2/AK which translates into the ten.

The defense would never do this from d = 2 (H / Hxx), as it would show
up when we lead the T, so then it would just cost a trick.

From d = 6 (Hxx / H) it would cost a trick if declarer plays for it.
But that possibility is not easily eliminated early on.  When the
defense multiplies 9x and 9H, it will always go for 9x with d = 6.

But even if declarer figured this out, he would still end up in
5/51, this time "knowing" that the central distribution (x/x) is the
only one.  Unfortunately the strategies has 2/AK because cashing the
ace has the result profile 1/A, 2/A, 1/A which lost out to
2/AK, 2/AK, 2/AK due to fewer tricks.

9/2076 refers to 9/2098, AK7 / T6 which only ever uses the king.
The same thing could and does happen here if declarer leads the 6:
The defense may crash the honors.  But declarer can also lead the ten,
sacricifing the card!  Now there is nothing to crash.  Declarer can
get the ten out of the way here and not in 9/2076.

So 9/2098 refers to 9/2164, AK8 / 76 which also uses only the king.

We can in principle keep strategies such as 1A 2A 1A vs 2AK 2AK 2AK
alive within a trick, but it is very unappealing to do this across
tricks.

So maybe we recognize when the parent has a worse profile than a
minimal, and we count (and fix?) these.


Premature reduction
...................

In 9/2645 (AQ/KJ9 missing Txxx), if we start with the 9, we get
#0 the trivial strategy (always needing AKQ), 
#1 9 to A, then overtake Q if the T shows up, wins a rank (AK) for d=3,
loses a rank (QJ) for d=1,
#2 9 to A, then always overtake Q, wins ranks (AK) for d=3,4,
loses ranks (QJ) for d=1,2.

If we start with J (which doesn't make sense), we get the same
trivial strategy #0; we don't get #2 as we can't afford always to
overtake; instead we get #1 which is similar to #1 above but
needing the 9 and not the QJ for d=1.
The #1 from J should lose to the #1 from 9.  But the #1 from 9
has already been eliminated (reduced), so #1 from 9 seems to survive.

This wouldn't show up in a minimals check, as the 9 would seem to
be needed (so 9/2645 would be minimal, needing the 9). The one needing
the jack would presumably be minimal as well.

The only solution seems to be not to reduce before the += step.
How much time and memory does this cost?

Update: Now that we don't lead the jack, it can't happen anymore.


Premature consolidation
.......................

In 7/1595 (KT9/Q) for the start Q J there are two strategies, each 
with pluses and minuses for declarer.  #1 (overtaking) needs 2N' 
in order not to lose on tricks anywhere to #0.  Then d = 7 (Kxx / x)
from Q x and Q A comes into play (1, KQ) and beats d = 7 in both
these strategies, so 2N' is no longer needed.  #0 and #1 survive.

In 7/1599 (KT8/Q), #1 loses on tricks to #0 as the 9 is missing,
even though #1 would win d = 6 on ranks. Again d = 7 is eliminated,
so now #1 would be competitive against #0, but it is too late.

The solution seems to be not to consolidate in the partner += step
already, and to wait for the lead += step (and the LHO *= step).
This probably costs memory and time.  I think I will wait with this
until I've done some other optimizations.  Or actually, only
consolidate away strategy's that are completely dominated, i.e.
every result is <=.

How it shows up: In 7/1595 there are 2 strategies, in the combination
of the two "minimals" only 1 (the same).  There should be 2.

Rare products
.............

In 8/1799 (AT/QJ9 missing Kxx) for the start Q and for d = 7 (Kxx/-),
West can duck and then declarer finesses (#0): 2, 2S as superficially,
only the queen is needed.  Later we multiply with Q K (cover) which
has 3/2NS' (QJT).  West will not cover, so it looks as if 2/2S is 
enough.  But 3/2NS' needs a lot more cards than 2/2S.  Concretely
it is in some sense possible to play Q K A for only 2 tricks by
somehow conceding after winning the jack.

3/2NS' in a sense has a profile of trick-taking capability:
3/2NS', 2/2S', 1/4N.  If we multiply this by 2/2S it should yield
2/2S' and not 2/2S.  The condition is more tricks with 2+ more
constraints in between them.  Then it may be possible to weaken
and still improve on the bound.

A trivial strategy stays trivial.

When adapting, we have a new winner (say 1/C) and a subsequent winner
(say 1/D).  We can make 2/(C*D).  We can also make 1/C or 1/D.
If C is more constrained, then we get 2/C and 1/D (as declarer gets
to choose the less constrained one if he gives up a trick).
1/D is only interesting if it is 2+ more relaxed than C.

In general, we can multiply one profile with another to preserve the
sums of tricks.  Then we can pick the most constrained way to get
a number of tricks (defense chooses).  Then we can prune some
declarer's choices of giving up tricks if it doesn't gain 2+ cards.

Again this takes memory and time.

if (tricks > result.tricks)
{
  if (! winner.empty() &&
      winner.getAbsNumber() + 1 < result.winner.getAbsNumber())
  {
  }
}
else if (tricks < result.tricks)
{
  if (! winner.empty() &&
      result.winner.getAbsNumber() + 1 < winner.getAbsNumber())
  {
  }
}

How it shows up: 3 strategies in 1799, 2 in the only minimal (1799).
In this case the third one shouldn't actually exist.

Overall partitioning
--------------------

* Can characterize solved, ranked combinations as canonical or not,
  and minimal or not (bit vector of bools?)

* CombEntry:cpp, e.g. setMinimal: review

Symmetrization
--------------

* For void starting with 10-13 cards (assuming we solve up to 13
  cards), it's always OK to symmetrize, as we can never get there
  from non-void combinations.  We do this:
  a. If we get above [100] strategies, we start over and only
     look up symmetrized strategies (so 6-8 and 8-6 are done together
     and symmetrized against each other).  Multiply strategy by
     strategy, I think, and don't do a complete cross
  b. In the end, if we are above [16] strategies, we symmetrize
  c. If we know from lookup that something must be symmetric

* A histogram of #strategies shows that we also get large numbers
  when South has a single card, e.g. 11/132887, KJ95 / 7 missing AQT864.
  Maybe it's OK to limit next strategies to symmetric ones, too,
  when South becomes void and there are a lot of next strategies.
  1606 strategies here.

* Symmetrize 11 / 132902, KJ96 / void: From ~ 9619 to 166 strategies.
  Similar to the square root.

* Actually, maybe the way to cut down is to gradually bump up
  the critical rank and eliminate strategies from below, until we
  arrive at a reasonable range?  And check that the eliminated ones
  are covered by trick vectors when we later forget about ranks?

  Like a rolling pruning?  Once cards == 10 are done, go over and
  turn some holdings into references to other because there are
  too many strategies.  So this is a new type, not minimal/
  canonical/oriented, but simplified from one rank to another.
  Just note its own rank, because the referred one also has a rank.


Optimizations
-------------
* If there is a Result per Strategy, equality can be tested first
  in this way.  And then one Result per group (Reduction).
  - One classical lowest result, one that takes history into account
  - In print output, show the result(s)

* Similarly when only < or > is possible.  Take the lowest one and
  its groups.

* Would it be worthwhile to store the minimal numbers in the Strategy
  as well?
  -- Then it would also be in the print output, in the table itself

* Optimize the code for Slist::minimal().  Is it even used?

* Probably Winners can really go away now -- always single-valued?
  MultiResult then too?

* Look at speeding up Slist::equalByMethod.
  Divide completely by size
  assert size(v1) >= size(v2)?

* Also optimize for Strategies == even though it doesn't matter
  - Start at ==, only do upper triangle of matrix

* Is Declarer::greater used?  Is it completely right?

* If space became really tight, the minimals in CombEntry could be
  indices in a central list (careful with multi-threading).  That would
  save the 24-byte overhead in each CombEntry at the cost of two
  4-byte counters and potentially an internal "iterator".  So it
  should save 12-16 bytes per CombEntry, and there are ~ 2m of them,
  so ~ 25 MB.

* Why more than 2x Ranks to Plays and Strategize at the end of output?

* No / limited endl


Ranks stored in tables
----------------------
* Write and read binary files with holdings to run vs. not
* Is it true that a minimal combination does not need non-minimal
  ones to solve?  If not, we would either solve the non-minimal
  ones, or look up the non-minimal one (probably better) and
  map the smaller number of distributions to the current case somehow


Mixed strategies
----------------
In the end we may not have to do so much LP.  EW must find play for
each distribution that work against all NS strategies.  EW get into
trouble when they need to vary their play depending on what NS do.
So we keep track of all plays that work in various situations, and we
take the intersection which is often not empty.

I'm hoping this will also give rise to the mandatory falsecards that
protect not this holding, but some other holding.

Perhaps represent all the NS strategies as some kind of tree with the
branching points that they will actually make use of.

In the end there will be the combinations with mixed potential.  But
I think we can do all the above independent of external constraints.
So we can actually tell in the abstract which combinations have the
potential for mixed strategies, even without knowing the constraints?!


Features
--------
* Distribution::limit, using a struct that Control returns
  - We will fail for now on some HCP values

* Not all features of Control.cpp are implemented yet

* Check sometime that these still work
  - Node optimization (on/off)
  - Strategies *= optimization (on/off)


Semantics, verbal descriptions
------------------------------
* Winning plays/strategies such as "cash ace"
  - Sometimes NS have several ways to reach its optimum; keep them all
* Noting the inequalities on EW plays that are needed to stabilize
  an NS strategy

Bugs
----
Why doesn't it work in Combination to make complete copies of
everything?  It must be some stray pointers, but where?

Is ResConvert::increment actually correct, or do we get too few
per group?!


-n AT5 -s Q876 does some other combination?
